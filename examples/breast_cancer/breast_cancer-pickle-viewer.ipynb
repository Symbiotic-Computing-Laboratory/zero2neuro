{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b4a48-b7e5-4214-a056-292a388af720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "# Will probably have to make look nicer but tried to make it as generic as possible. \n",
    "# Assume the directory for the results is a subdirectory of working directory.\n",
    "directory ='./results' \n",
    "for filename in os.listdir(directory): # For each file in directory\n",
    "    if filename.endswith('.pkl'): # Find files that are pickle files\n",
    "        file_path = os.path.join(directory, filename) # Get the file path for those files\n",
    "        with open(file_path, 'rb') as pickle_file: # Open the files\n",
    "            data = pickle.load(pickle_file) # Grab the data from pickle\n",
    "            plt.plot(data['history']['loss'], label=filename) # Grab the loss data and plot\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epoch/Loss')\n",
    "plt.grid(True)\n",
    "plt.legend() # Show the legend\n",
    "# Saving functions\n",
    "# plt.savefig(\"file/path.png\") \n",
    "# plt.savefig(\"file/path.pdf\")\n",
    "plt.show() # Show plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da36af65-8854-48b4-8431-4f7dda179a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data and what model predicted\n",
    "# print('Training Data\\n', data['ins_training'])\n",
    "# print('Output Data\\n', data['outs_training'])\n",
    "# print('What the model predicted\\n', data['predict_training'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea28e2-db4f-4d6e-b52b-4d105e2f2e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "array = np.round(data['predict_training']*100) # Turn the predicion floats into proper percentages\n",
    "index = 0 # Track index\n",
    "y = 0 # variable for incrementing output_mapping\n",
    "d = {} # dictionary for keeping track of outputs\n",
    "d_errors = {} # dictionary for tracking what got a class error\n",
    "class_error = 0 # variable to track classification errors\n",
    "for output in data['dataset']['output_mapping']:\n",
    "    d[data['dataset']['output_mapping'][y]] = 0\n",
    "    d_errors[data['dataset']['output_mapping'][y]] = 0\n",
    "    y+=1    \n",
    "    \n",
    "###\n",
    "# Look at each array inside of the array and find the prediction the model made and display that\n",
    "# prediction along with the percentages and index.\n",
    "for x in array: \n",
    "    print('Prediction:', data['dataset']['output_mapping'][np.argmax(x)],'| Confidence:', x,'| Index:', index)\n",
    "    d[data['dataset']['output_mapping'][np.argmax(x)]] += 1\n",
    "    if data['outs_training'][index] != np.argmax(x):\n",
    "        class_error += 1\n",
    "        d_errors[data['dataset']['output_mapping'][np.argmax(x)]] +=1\n",
    "    index += 1\n",
    "\n",
    "# Display the total\n",
    "print('\\n\\nTotal amount of predictions per class\\n', d)\n",
    "print('\\nTotal number of classification errors\\n', class_error)\n",
    "print('\\nClassification Errors\\n', d_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06eb0a2-3a18-4207-83fd-198088bd18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/breast_cancer_R04_results.pkl', 'rb') as pickle_file:\n",
    "    data = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef586a06-1e97-4e98-9fe0-49b33f380517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# There has to be a better way to do this code\n",
    "true_values = np.array(data['outs_training'])\n",
    "array = np.array(data['predict_training'])\n",
    "predictions = []\n",
    "index = 0 # Track index\n",
    "\n",
    "# Making a new array because sklearn really doesn't like sparse arrays. \n",
    "for x in array: \n",
    "    predictions = np.append(predictions,np.argmax(x))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf64b05-38a3-467a-8fe7-85da92f03721",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(true_values, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fae6cd-e7a5-4817-bfbc-6b8b0e31821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to make generic, has weird text on top\n",
    "sns.heatmap(confusion_matrix, cmap='Blues', cbar=False, annot=True, fmt=\"d\")\n",
    "plt.xticks(np.arange(2)+0.5,['B','M'])\n",
    "plt.yticks(np.arange(2)+0.5,['B','M'])\n",
    "plt.xlabel(\"Predicted Classes\")\n",
    "plt.ylabel(\"Actual Classes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
